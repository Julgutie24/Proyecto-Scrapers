from playwright.sync_api import sync_playwright
from herramientas import process_text


class WikiScraper:
    def scraper(self, urls):
        """
        Permite al usuario seleccionar una secci√≥n de Wikipedia y extraer su contenido.
        Usa Playwright para navegar y scrapear din√°micamente.
        """
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=False)
            page = browser.new_page()

            for url in urls:
                page.goto(url, timeout=60000)

                # Obtener secciones <h2>, ignorando algunas que no tienen texto relevante
                sections = page.locator("h2").all_inner_texts()
                banned = {
                    "Contenidos", "V√©ase tambi√©n", "Referencias",
                    "Enlaces externos", "Bibliograf√≠a"
                }
                filtered = [s for s in sections if s not in banned]
                filtered_ = ["Introducci√≥n"] + filtered

                if not sections:
                    print("‚ùå No se encontraron secciones.")
                    continue

                # Mostrar secciones al usuario
                print("\nüìå Secciones disponibles:")
                for i, sec in enumerate(filtered_):
                    print(f"{i + 1}. {sec}")

                try:
                    select = int(input("üëâ Elija la secci√≥n escribiendo el n√∫mero: "))
                    selected_section = filtered_[select - 1]

                    print(f"\n‚úÖ Secci√≥n seleccionada: {selected_section}")
                    print("\nüìÑ Procesando contenido...\n")

                    full_text = ""
                    count = 0

                    # Caso especial: Introducci√≥n (antes del primer <h2>)
                    if selected_section == "Introducci√≥n":
                        paragraphs = page.locator("p")
                        for i in range(paragraphs.count()):
                            nodo = paragraphs.nth(i)

                            # Parar si se detecta un encabezado (h2) antes del p√°rrafo
                            prev = nodo.locator("xpath=preceding-sibling::h2")
                            if prev.count() > 0:
                                break

                            text = nodo.inner_text()
                            if not text:
                                continue

                            full_text += text + "\n\n"
                            count += 1
                            if count >= 3:
                                break

                    # Para otras secciones
                    else:
                        secciones_divs = page.locator("div.mw-heading.mw-heading2")
                        matched_div = None

                        # Buscar el div <h2> que coincide con la secci√≥n seleccionada
                        for i in range(secciones_divs.count()):
                            div = secciones_divs.nth(i)
                            h2 = div.locator("h2")

                            if h2.count() > 0 and h2.inner_text() == selected_section:
                                matched_div = div
                                break

                        if matched_div:
                            siblings = matched_div.locator("xpath=following-sibling::*")

                            for i in range(siblings.count()):
                                node = siblings.nth(i)

                                # Parar si se llega a otro t√≠tulo de secci√≥n
                                class_name = node.get_attribute("class") or ""
                                if "mw-heading2" in class_name:
                                    break

                                # Agregar p√°rrafos
                                if node.evaluate("el => el.tagName") == "P":
                                    text = node.inner_text()
                                    if not text:
                                        continue

                                    full_text += text + "\n\n"
                                    count += 1
                                    if count >= 3:
                                        break
                        else:
                            print("‚ùå No se encontr√≥ la secci√≥n en el DOM.")
                            continue

                    # Resultado
                    if not full_text:
                        print("‚ö†Ô∏è No se encontr√≥ texto en esta secci√≥n.")
                    else:
                        process_text(url, selected_section, full_text)

                except (ValueError, IndexError):
                    print("‚ùå Selecci√≥n inv√°lida. Intente de nuevo.")

            browser.close()
